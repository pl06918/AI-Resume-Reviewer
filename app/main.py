from __future__ import annotations

import streamlit as st
import plotly.graph_objects as go

from modules.llm_feedback import generate_llm_feedback
from modules.resume_parser import extract_resume_text
from modules.scorer import review_resume

st.set_page_config(page_title="AI Resume Reviewer", page_icon="ğŸ“„", layout="wide")

st.title("ğŸ“„ AI Resume Reviewer")
st.caption("UGA Hackathon ì œì¶œìš© MVP - Resume/JD ê¸°ë°˜ ìë™ í”¼ë“œë°±")

with st.sidebar:
    st.header("ì„¤ì •")
    use_llm = st.toggle("LLM ìƒì„¸ í”¼ë“œë°± ì‚¬ìš© (OPENAI_API_KEY í•„ìš”)", value=False)
    st.markdown("ì§€ì› íŒŒì¼: PDF, DOCX, TXT")

col1, col2 = st.columns([1, 1])

with col1:
    uploaded_resume = st.file_uploader("ì´ë ¥ì„œ ì—…ë¡œë“œ", type=["pdf", "docx", "txt"])

with col2:
    jd_text = st.text_area(
        "Job Description ì…ë ¥ (ì„ íƒ)",
        height=250,
        placeholder="ì±„ìš© ê³µê³  ë‚´ìš©ì„ ë¶™ì—¬ë„£ìœ¼ë©´ JD ë§¤ì¹­ ì ìˆ˜ê°€ ê³„ì‚°ë©ë‹ˆë‹¤.",
    )

if uploaded_resume:
    file_bytes = uploaded_resume.read()
    resume_text = extract_resume_text(uploaded_resume.name, file_bytes)

    if not resume_text:
        st.error("íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì½ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í˜•ì‹ìœ¼ë¡œ ë‹¤ì‹œ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
    else:
        result = review_resume(resume_text, jd_text)

        s1, s2, s3, s4 = st.columns(4)
        s1.metric("Overall", f"{result.overall_score}/100")
        s2.metric("JD Match", f"{result.jd_match_score}/100")
        s3.metric("ATS", f"{result.ats_score}/100")
        s4.metric("Impact", f"{result.impact_score}/100")

        fig = go.Figure(
            data=[
                go.Bar(
                    x=["JD Match", "ATS", "Section", "Impact"],
                    y=[
                        result.jd_match_score,
                        result.ats_score,
                        result.section_score,
                        result.impact_score,
                    ],
                    marker_color=["#0068c9", "#00a3a3", "#f39c12", "#27ae60"],
                )
            ]
        )
        fig.update_layout(height=320, margin=dict(l=20, r=20, t=20, b=20), yaxis_range=[0, 100])
        st.plotly_chart(fig, use_container_width=True)

        c1, c2 = st.columns(2)

        with c1:
            st.subheader("ê°•ì ")
            for s in result.strengths:
                st.write(f"- {s}")

            st.subheader("ëˆ„ë½ í‚¤ì›Œë“œ")
            if result.missing_keywords:
                st.write(", ".join(result.missing_keywords))
            else:
                st.write("ëˆ„ë½ëœ í•µì‹¬ í‚¤ì›Œë“œê°€ ê±°ì˜ ì—†ìŠµë‹ˆë‹¤.")

        with c2:
            st.subheader("ê°œì„  í¬ì¸íŠ¸")
            for i in result.improvements:
                st.write(f"- {i}")

            st.subheader("ë©´ì ‘ ì˜ˆìƒ ì§ˆë¬¸")
            for q in result.interview_questions:
                st.write(f"- {q}")

        with st.expander("ì¶”ì¶œëœ ì´ë ¥ì„œ í…ìŠ¤íŠ¸ ë³´ê¸°"):
            st.text_area("Resume Text", resume_text, height=300)

        if use_llm:
            with st.spinner("LLM í”¼ë“œë°± ìƒì„± ì¤‘..."):
                llm_feedback = generate_llm_feedback(resume_text, jd_text)
            if llm_feedback:
                st.subheader("LLM ìƒì„¸ í”¼ë“œë°±")
                st.markdown(llm_feedback)
            else:
                st.info("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•Šì•„ LLM í”¼ë“œë°±ì€ ê±´ë„ˆëœë‹ˆë‹¤.")
else:
    st.info("ì´ë ¥ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ ë¶„ì„ì´ ì‹œì‘ë©ë‹ˆë‹¤.")
